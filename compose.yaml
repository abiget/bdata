x-common-env: &common-env
  KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
  POSTGRES_DB:        ${POSTGRES_DB}
  POSTGRES_USER:      ${POSTGRES_USER}
  POSTGRES_PASSWORD:  ${POSTGRES_PASSWORD}
  POSTGRES_PORT:      ${POSTGRES_PORT}
  POSTGRES_URL:       ${POSTGRES_URL}
  POSTGRES_HOST:      ${POSTGRES_HOST}

services:
  # application service
  app:
    build: ./dashboard
    container_name: price-intelligence-app
    ports:
      - ${STREAMLIT_PORT}:8501 # Map host port to container port
    depends_on:
      postgres:
        condition: service_healthy
      broker:
        condition: service_healthy
    networks:
      - common-network
    volumes:
      - ./dashboard/app:/app # Mount application code

    environment:
      APP_ENV: ${APP_ENV}
      <<: *common-env
    healthcheck:
      test: curl --fail http://localhost:8501 || exit 1
      interval: 10s
      timeout: 5s
      retries: 3
  # ----------------------Clean----------------------  
  competitor_price_producer:
    build:
      context: ./data_gen
      dockerfile: src/producers/Dockerfile
    container_name: competitor_price_producer
    command: ["python3", "-u", "src/producers/competitor_price_producer.py"]
    depends_on:
      broker:
        condition: service_healthy
    networks:
      - common-network
    # volumes:
    #   - ./data_gen/src/producers:/data_gen/producers 
    #   - ./data_gen/src/common:/data_gen/common 
    #   - ./data_gen/src/data:/data_gen/data 
    environment:
      <<: *common-env
  user_behavior_producer:
    build:
      context: ./data_gen
      dockerfile: src/producers/Dockerfile
    container_name: user_behavior_producer
    command: ["python3", "-u", "src/producers/user_behavior_producer.py"]
    depends_on:
      broker:
        condition: service_healthy
    networks:
      - common-network
    # volumes:
    #   - ./data_gen:/user_behaviour # Mount application code

    environment:
      <<: *common-env
  # ----------------Clean----------------------

  # PostgreSQL database
  postgres:
    image: postgres:latest
    container_name: postgres-db
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_HOST_AUTH_METHOD: trust # Allow connections without password for local development
      POSTGRES_PORT: 5432  # Specify the port for PostgreSQL
    volumes:
      - type: tmpfs # Use tmpfs for /dev/shm for better performance from in memory operations like caching
        target: /dev/shm
        tmpfs:
          size: 268435456  # 256 MB

      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init.sql:/docker-entrypoint-initdb.d/init.sql # Initialize database with SQL script and postgres will run it
    ports:
      - "${POSTGRES_PORT}:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
    networks:
      - common-network

  # Kafka broker service
  broker:
    image: apache/kafka:latest
    hostname: broker
    container_name: kafka-broker
    ports:
      - 9092:9092 # External port for host machine access
    environment:
      # Basic Kafka configuration
      KAFKA_BROKER_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: ${KAFKA_SECURITY_PROTOCOL}:${KAFKA_SECURITY_PROTOCOL},PLAINTEXT_HOST:${KAFKA_SECURITY_PROTOCOL},CONTROLLER:${KAFKA_SECURITY_PROTOCOL}
      KAFKA_ADVERTISED_LISTENERS: ${KAFKA_SECURITY_PROTOCOL}://broker:29092,PLAINTEXT_HOST://localhost:9092

      # KRaft mode configuration
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_NODE_ID: 1
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@broker:29093
      KAFKA_LISTENERS: ${KAFKA_SECURITY_PROTOCOL}://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092 # cross network
      KAFKA_INTER_BROKER_LISTENER_NAME: ${KAFKA_SECURITY_PROTOCOL}
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Performance and replication settings
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

      # Storage configuration
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

    volumes:
      - kafka-data:/var/lib/kafka/data # Persist Kafka data
    networks:
      - common-network
    healthcheck:
      test: [ "CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1" ]
      interval: 10s
      timeout: 10s
      retries: 15
      start_period: 30s


# Optional: Kafka UI for monitoring
  kafka-ui:
    image: kafbat/kafka-ui:main
    ports:
      - ${KAFKA_UI_PORT}:8080  # Web UI port
    environment:
      DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: ${KAFKA_BOOTSTRAP_SERVERS}
      KAFKA_CLUSTERS_0_METRICS_PORT: 9092
      KAFKA_CLUSTERS_0_READONLY: "false"
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
    depends_on:
      broker:
        condition: service_healthy  # Wait for broker to be healthy
    networks:
      - common-network
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/ || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s
# -----------------------------------------------------------------------------------------
  sql-client:
    build: ./processing
    container_name: sql-client
    command: bin/sql-client.sh
    depends_on:
      - jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        rest.address: jobmanager
    networks:
      - common-network

  jobmanager:
    build: ./processing
    container_name: jobmanager
    ports:
      - "8081:8081"
    command: standalone-job --python /opt/flink/processing/src/jobs/price_analyzer.py
    volumes:
      - ./processing:/opt/flink/processing
      - flink_data:/tmp/
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
        rest.flamegraph.enabled: true
        web.backpressure.refresh-interval: 10000
        execution.shutdown-on-application-finish: false
    networks:
      - common-network
  taskmanager:
    build: ./processing
    container_name: taskmanager

    command: taskmanager
    volumes:
      - flink_data:/tmp/
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: jobmanager
        taskmanager.numberOfTaskSlots: 3
        state.backend: filesystem
        state.checkpoints.dir: file:///tmp/flink-checkpoints
        heartbeat.interval: 1000
        heartbeat.timeout: 5000
    networks:
      - common-network

  # price_consumer:
  #   build:
  #     context: ./data_gen
  #     dockerfile: Dockerfile
  #   command: ["python3", "-u", "consumers/price_consumer.py"]
  #   container_name: price_consumer
  #   environment:
  #     PRODUCER_SCRIPT: consumers/price_consumer.py
  #   depends_on:
  #     - broker
  #     - postgres
  #   networks:
  #     - common-network

  # price_analyzer:
  #   build:
  #     context: ./processing
  #     dockerfile: Dockerfile
  #   container_name: price_analyzer
  #   environment:
  #     - KAFKA_BOOTSTRAP_SERVERS=broker:29092
  #   depends_on:
  #     - broker
  #     - postgres
  #     - jobmanager
  #     - taskmanager
  #     - competitor_price_producer
  #     - user_behavior_producer
  #   networks:
  #     - common-network
# -----------------------------------------------------------------------------------------

# Networks
networks:
  common-network:
  
# Volumes
volumes:
  kafka-data:
  postgres_data:
  flink-checkpoints:
  flink_data:
